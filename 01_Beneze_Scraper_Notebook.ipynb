{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import time\n",
    "import glob\n",
    "import os\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fills out the search page\n",
    "def search_page(start_date, end_date, CFR_Part, CFR_Subpart):\n",
    "    \"\"\"This function fills out the search page for EPA's Webfire Report Search.\n",
    "    Parameters:\n",
    "    start_date: the start date you want for your document search\n",
    "    end_date: the end date you want for your document search\n",
    "    CFR_Part: the regulatory part of interest\n",
    "    CFR_Subpart: the regulatory subpart of interest\"\"\"\n",
    "\n",
    "    date = driver.find_element_by_id('ui-id-3')\n",
    "    date.click()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    search_start = driver.find_element_by_name(\"startdate\")\n",
    "    search_start.send_keys(start_date)\n",
    "    search_end = driver.find_element_by_name(\"enddate\")\n",
    "    search_end.send_keys(end_date)\n",
    "    \n",
    "    reg = driver.find_element_by_id('ui-id-7')\n",
    "    reg.click()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    part = Select(driver.find_element_by_id('CFRpart'))\n",
    "    part.select_by_value(CFR_Part)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    subpart = Select(driver.find_element_by_id('CFRSubpart'))\n",
    "    subpart.select_by_value(CFR_Subpart)\n",
    "\n",
    "    submit = driver.find_element_by_id('Submit')\n",
    "    submit.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pulls zip files from results page\n",
    "def results_page():\n",
    "    \"\"\"This pulls the download links for each facility that appears on the results page as well as the document names.\"\"\"\n",
    "    page_links = []\n",
    "    doc_names = []\n",
    "    \n",
    "    table = driver.find_element_by_id('myDocTable')\n",
    "    docs = table.find_elements_by_tag_name('a')\n",
    "    \n",
    "    for doc in docs:\n",
    "        page_links.append(doc.get_attribute('href'))\n",
    "        doc_names.append(doc.get_attribute('title'))\n",
    "    \n",
    "    return page_links, doc_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grabbing information from parameters spreadsheet\n",
    "df = pd.read_excel('03_Parameters.xlsx')\n",
    "start = df.start_date[0]\n",
    "end = df.end_date[0]\n",
    "part = df.CFR_Part[0]\n",
    "subpart = df.CFR_Subpart[0]\n",
    "page_count = df.pages[0]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Scraping download links from Webfire Reports Page\n",
    "driver_path = \"C:/Users/kkelderman/Documents/Python Scripts/chromedriver.exe\" #This should be changed to the location of your driver\n",
    "driver = webdriver.Chrome(driver_path)\n",
    "driver.get(\"https://cfpub.epa.gov/webfire/reports/esearch2.cfm\")\n",
    "\n",
    "search_page(start_date=start, end_date=end, CFR_Part=part, CFR_Subpart=subpart)\n",
    "time.sleep(2)\n",
    "\n",
    "link_list = []\n",
    "name_list = []\n",
    "\n",
    "for x in range(1,page_count):\n",
    "    page_links, doc_names = results_page()\n",
    "    link_list.append(page_links)\n",
    "    name_list.append(doc_names)\n",
    "    button = driver.find_element_by_id(\"myDocTable_next\")\n",
    "    button.click()\n",
    "    time.sleep(2)\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "all_links = [item for sublist in link_list for item in sublist]\n",
    "all_names = [item for sublist in name_list for item in sublist]\n",
    "\n",
    "new_names = []\n",
    "\n",
    "for count, name in enumerate(all_names):\n",
    "    new = '{}_{}'.format(count,name)\n",
    "    new_names.append(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating subfolder in directory for files to be downloaded\n",
    "day = date.today().strftime(\"%b-%d-%Y\")\n",
    "dest = os.path.abspath(os.getcwd()) + '\\\\Downloads_{}'.format(day)\n",
    "os.mkdir(dest)\n",
    "\n",
    "#Downloading and unzipping the files from the scraped links\n",
    "for i in range(0,len(all_links)):\n",
    "    path = '{}\\\\{}'.format(dest,new_names[i]) \n",
    "    link = all_links[i]\n",
    "    urllib.request.urlretrieve(link,path)\n",
    "\n",
    "all_zips = glob.glob(dest + \"\\*.zip\")\n",
    "\n",
    "for zip_ in all_zips:\n",
    "    prefix = zip_[71:74]\n",
    "    zipdata = zipfile.ZipFile(zip_)\n",
    "    zipinfos = zipdata.infolist()\n",
    "    \n",
    "    for zipinfo in zipinfos:\n",
    "        zipinfo.filename = prefix + zipinfo.filename\n",
    "        zipdata.extract(zipinfo, path='{}\\\\Unzipped_Files'.format(dest))\n",
    "    \n",
    "    zipdata.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
